{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Sentiment Analysis App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* Sentiment Analysis is a very popular functionality. For example, be able to determine if a product review is positive or negative.\n",
    "* Our app will be able to do more than that. It will be a text classification app, also called a \"tagging\" app.\n",
    "* In short, we will create an app to classify text into labels. And these labels can be:\n",
    "    * Sentiment: Sentiment Analysis app.\n",
    "    * Language: Language Analysis app.\n",
    "    * Style (formal, informal, etc): Style Analysis app.\n",
    "    * Topics or categories: Topic or category Analysis app.\n",
    "    * Political tendency: Political Analysis app.\n",
    "    * Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd19cd0-37f2-4e01-b9bd-a25b4fe5ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "## Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0a7f6-2a90-4838-b7d0-938dc3b70136",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f7ce6-1595-4e82-b9b7-fd0702744e4d",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Groq API key: gsk_...\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# Access the API key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Use it (example)\n",
    "print(f\"Using Groq API key: {groq_api_key[:4]}...\")  # Print partial for safety\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\",  # Options: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e7b7a-9906-487a-b86f-da65e78a1f6e",
   "metadata": {},
   "source": [
    "* Instead of using the previous llm, we will define a new llm in the following block of code and use the with_structured_output method supported by OpenAI models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8db0af-f068-4932-8151-418befd5c11d",
   "metadata": {},
   "source": [
    "## Tag Definition\n",
    "* In the following code we define the 3 tags we will analize in this app:\n",
    "    * sentiment.\n",
    "    * political tendency.\n",
    "    * language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9979cb1c-04c2-4c89-b9f0-92284d604e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# Define your schema\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text, e.g., positive, negative, or neutral\")\n",
    "    political_tendency: str = Field(description=\"The political tendency of the user, e.g., left, right, or neutral\")\n",
    "    language: str = Field(description=\"The language the text is written in, e.g., English, Hindi, etc.\")\n",
    "\n",
    "# Set up the LLM with your key (make sure it's loaded correctly)\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")  # Ensure this is set in your .env\n",
    ")\n",
    "\n",
    "# Better prompt\n",
    "tagging_prompt = ChatPromptTemplate.from_messages([\n",
    "     (\"system\", \n",
    "     \"You are an expert text classifier. For any given passage, extract the following fields:\\n\"\n",
    "     \"- {{\\\"sentiment\\\"}}: positive, negative, or neutral\\n\"\n",
    "     \"- {{\\\"political_tendency\\\"}}: left, right, or neutral\\n\"\n",
    "     \"- {{\\\"language\\\"}}: the language in which the text is written\\n\"\n",
    "     \"Return the output as strict JSON only, matching this structure:\\n\"\n",
    "     \"{{\\\"sentiment\\\": \\\"...\\\", \\\"political_tendency\\\": \\\"...\\\", \\\"language\\\": \\\"...\\\"}}\")\n",
    ",\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain=tagging_prompt|llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2bd551d-f8a3-4664-a7bf-da73caef1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_follower = \"I'm confident that President Trump's leadership and track record will once again resonate with Americans. His strong stance on economic growth and national security is exactly what our country needs at this pivotal moment. We need to bring back the proven leadership that can make America great again!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbd956fc-15a9-4a32-982c-642bce35a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_follower = \"I believe President Biden's compassionate and steady approach is vital for our nation right now. His commitment to healthcare reform, climate change, and restoring our international alliances is crucial. It's time to continue the progress and ensure a future that benefits all Americans.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f7ed3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "response = chain.invoke({\"input\": trump_follower})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5859015a-f0f0-439e-85eb-d9320aba0c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='positive' political_tendency='right' language='en'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    data = json.loads(response.content)\n",
    "    result = Classification(**data)  # Optional validation with Pydantic\n",
    "    print(result)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"‚ùå LLM did not return valid JSON:\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8abf4cb6-2f8f-43f9-a32e-bf5a4658de54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n  \"sentiment\": \"positive\",\\n  \"political_tendency\": \"left\",\\n  \"language\": \"en\"\\n}', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 153, 'total_tokens': 180, 'completion_time': 0.024694191, 'prompt_time': 0.01808207, 'queue_time': 0.273783569, 'total_time': 0.042776261}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None}, id='run--7800a171-09a3-43e1-9441-7588b5a08707-0', usage_metadata={'input_tokens': 153, 'output_tokens': 27, 'total_tokens': 180})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": biden_follower})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f5093-d6fa-4dfe-a238-03b5de700d17",
   "metadata": {},
   "source": [
    "* Careful schema definition gives us more control over the model's output.\n",
    "* Specifically, we can define:\n",
    "    * Possible values for each property.\n",
    "    * Description to make sure that the model understands the property.\n",
    "    * Required properties to be returned.\n",
    "* Let's redeclare our Pydantic model to control for each of the previously mentioned aspects **using enums**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ff0c920-3669-444f-a5d3-b1a951a86071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    political_tendency: str = Field(\n",
    "        ...,\n",
    "        description=\"The political tendency of the user\",\n",
    "        enum=[\"conservative\", \"liberal\", \"independent\"],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "705936c4-4845-42c5-821b-10a23a1823f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"Classify the following text and return valid JSON with exactly these fields:\\n\"\n",
    "     \"sentiment (positive, negative, neutral),\\n\"\n",
    "     \"political_tendency (left, right, neutral),\\n\"\n",
    "     \"language (e.g., English, Hindi)\\n\\n\"\n",
    "     \"Return only JSON, no explanation.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama3-8b-8192\", groq_api_key=os.getenv(\"GROQ_API_KEY\"), temperature=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8260857-6002-4657-a31f-b9f55fbbacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = tagging_prompt | llm  # no structured output\n",
    "response = tagging_chain.invoke({\"input\": trump_follower})\n",
    "import json\n",
    "parsed = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e91f1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'positive', 'political_tendency': 'right', 'language': 'English'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde88b3e-4de2-4890-b858-ab2f326be5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There is no \"Classification\" function mentioned in the passage. The passage is an opinion piece about President Biden\\'s approach and policies. It does not contain any information about properties or classification.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 84, 'total_tokens': 122, 'completion_time': 0.033941792, 'prompt_time': 0.037375023, 'queue_time': 1.228757428, 'total_time': 0.071316815}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None}, id='run--79b28c94-78a8-4f3d-8bfe-7fff6c307807-0', usage_metadata={'input_tokens': 84, 'output_tokens': 38, 'total_tokens': 122})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging_chain.invoke({\"input\": biden_follower})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1bf7b-7a83-49f4-a48d-80c1b0654731",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-sentiment-analysis.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-sentiment-analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f89427-480e-4993-b0a0-ce6075cac451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
